---
date: 2025-04-25
title: RAG优化策略
description: 分步骤构建 查询转换、路由、问题构建、索引、检索、生成 的优化策略
mermaid: true
mathjax: true
category: [RAG]
tags: [RAG, 大模型, 智能体, 优化策略]
ogImage: https://astro-yi.obs.cn-east-3.myhuaweicloud.com/avatar.png
---

一个完整的 RAG（Retrieval-Augmented Generation，检索增强生成）应用开发流程，涉及到**文档加载器、向量数据库、检索器、Prompt、记忆、输出解析器、大语言模型**等多个功能模块。  

对于 Transformer架构类型的大模型来说，想要提高LLM生成内容的准确性，一般只需要 3 个步骤：  

1. **提供更准确的内容**：让 LLM 能识别到关联的内容，生成的内容准确性更高。  
2. **让重要的内容更靠前**：GPT 模型的注意力机制会让传递 Prompt 中更靠前的内容权重更高，越靠后权重越低。  
3. **不传递不相关内容**：缩短每个块的大小，尽可能让每个块只包含关联的内容，缩小不相关内容的比例。  

:::tip 
但是！复杂的优化流程，响应时间会变慢，而且使用的策略越多，幻觉会叠加。需要权衡。
:::

![RAG优化策略框架](/pic/RAG优化策略/RAG优化策略框架.png)


## 查询转换

### 查询重写和融合策略

如果直接使用原始问题进行检索，可以因为用户的表述偏差导致检索不到相关的文档。  

- 利用大语言模型（LLM）对原始问题进行扩展、分解或抽象，**生成多个语义相关但视角不同的子查询**，从而提高检索系统对用户意图的覆盖能力。
- 通常使用 **参数较小的本地模型 + 针对性优化的 promp**t 即可完成任务，并将 temperature 设置为 0，确保生成的文本更加有确定性。

![查询重写和融合策略](/pic/RAG优化策略/查询重写和融合策略.png)

```
你的任务是为给定的用户问题生成3 - 5个语义等价但表述差异化的查询变体，目的是帮助用户克服基于距离的相似性搜索的一些局限性，以便从向量数据库中检索相关文档。
以下是原始问题：
<question>
{{question}}
</question>
请生成3 - 5个语义与原始问题等价，但表述不同的查询变体，用换行符分隔这些替代问题。
请在<查询变体>标签内写下你的答案。
```

在多查询重写策略中，每个子问题都会检索出相应的文档片段。如何**合并这些问题的结果**，主要思想对其检索结果进行**重新排序**（即 reranking）后输出 Top K 个结果，最后再将这 Top K 个结果喂给 LLM 并生成最终答案。通常使用的算法是**RRF(Reciprocal Rank Fusion)**，即倒排序排名算法。


### 问题分解策略

**复杂问题**由多个问题按顺序步骤组成，执行相似性搜索时，向量数据库存储的都是基础文档数据，往往相似度低，但是这些数据在现实世界又可能存在很大的关联（文本嵌入模型的限制，一条向量不可能无损记录段落信息）。  

- 将一个复杂问题**分解成多个子问题或者子步骤**。问题分解后的子问题跟原始问题是“父子”关系，而查询重写跟原始问题则是“兄弟”关系。
  - **串行模式**：适用于逻辑依赖强的问题分解，确保步骤的连贯性。例如，“RAG 都有哪些阶段？”需要先找到都有哪些阶段，然后再询问各个阶段该做什么事情。
  - **并行模式**：适用于独立子任务的高效处理，提升响应速度。例如，“如何规划北京到上海的 5 天旅游行程？”需要分解成交通、住宿、景点三个子问题，分别完成。

### 问题回退策略

和问题分解策略相反，当用户**问题非常具体**时，可能无法检索到对应文档，就**需要将问题进行抽象**。例如，“李开复在 2000 年是在哪个公司工作？”可以重新抽象成“李开复的工作经历是什么？”。  
-- 适用于 时间敏感问题（需整合时间线）、多跳推理、 STEM 问题（需公式应用）。  

> **原始问题**：1954 年 8 月至 11 月期间，埃斯特拉・利奥波德就读于哪所学校？  
> 1948 年，威斯康星大学麦迪逊分校，植物学学士；  
> 1950 年，加州大学伯克利分校，植物学硕士；  
> 1955 年，耶鲁大学，植物学博士。  
> **直接回答的答案**：1954 年 8 月至 11 月期间，埃斯特拉・利奥波德就读于威斯康星大学麦迪逊分校。  
> **回溯问题**：埃斯特拉・利奥波德的教育经历是怎样的？  
> **最终答案**：她 1955 年就读于耶鲁大学植物学博士项目。因此，1954 年 8 月至 11 月期间，埃斯特拉・利奥波德最可能就读于耶鲁大学。

### HyDE 混合策略

query 和 doc 之间是不对称检索。例如，“今天回家的路上看到了美丽的风景，非常开心！想学习 python 该怎么办？”这个请求中，前面的风景、开心等词语均为无关信息，会对真实的请求“学习 python”产生干扰。如果直接搜索用户的请求，可能会产生不正确或无法回答的 LLM 响应。因此，有必要使得**用户查询的语义空间与文档的语义空间保持一致**。  
- 生成假设文档 + 对比编码检索。
![HyDE策略](/pic/RAG优化策略/HyDE策略.png)

1. 生成假设文档：利用指令遵循的语言模型（如 InstructGPT）根据查询生成虚构但具有相关性的假设文档。生成过程通过自然语言指令（如 “写一个回答问题的段落”）引导，无需标注数据。  
2. 对比编码检索：使用无监督对比学习的编码器（如 Contriever）将生成的假设文档编码为向量，在语料库嵌入空间中检索最相似的真实文档。编码器的密集瓶颈可过滤假设文档中的错误细节，将生成内容与实际语料对齐。

### 混合检索策略

- **稀疏检索器**：基于关键词匹配，利用词频（TF）和逆文档频率（IDF）计算文档与查询的相关性，非常高效，无需训练、对明确关键词匹配效果好；但无法捕捉语义（如同义词、上下文相关性）。  
- **密集检索器**：使用深度学习模型生成密集向量表示，通过向量相似度（如余弦相似度）衡量相关性，捕捉语义信息，解决词汇不匹配问题；但计算成本高，对生僻词敏感。  

**解决方法**：混合检索策略就是将多种检索方式混合起来，可以利用不同算法的优势，从而获得比任何单一算法更好的性能。  

![混合检索](/pic/RAG优化策略/混合检索.png)

## 路由

### 数据源路由

在 RAG 应用开发中，如果想**根据不同的问题检索不同的向量数据库**，只需要**设定对应的 Prompt**，然后让 LLM 根据传递的问题返回需要选择的向量数据库的名称，再根据得到的名称选择不同的检索器即可。  

![数据源路由](/pic/RAG优化策略/数据源路由.png)


### Prompt 路由

如果能针对用户的提问，例如用户提问的内容是数学相关的则使用数学的模板，提问的内容是物理相关的则使用物理的模板，**针对性选择不同的模板**，LLM 生成的内容会比使用通用模板更好。

```
你将扮演一位非常聪明的物理教授，以简洁易懂的方式回答物理问题。当你不知道问题的答案时，要坦率承认自己不知道。
以下是需要你回答的物理问题：
<query>
{{query}}
</query>
在回答问题时，请遵循以下指南：
1. 确保回答简洁易懂。
2. 如果不知道问题的答案，直接表明“我不知道这个问题的答案”。
请在<回答>标签内写下你的答案。
```

```
你将扮演一位非常优秀的数学家，专门负责回答数学问题。你需要将复杂的问题分解成多个小步骤，回答这些小步骤，然后将它们整合起来回答更广泛的问题。
这是需要你解答的数学问题：
<问题>
{{query}}
</问题>
在解答问题时，请按照以下步骤进行：
1. 仔细阅读问题，理解问题的核心。
2. 将问题分解成多个小步骤。
3. 依次解答每个小步骤。
4. 最后将小步骤的解答整合起来，给出完整的答案。
请在<回答>标签内写下你的答案，确保答案清晰、全面且包含每一个关键步骤。
```

## 问题构建

### 自查询

检索外部数据时，最后在执行检索的时候使用的都是固定的筛选条件（没有附加过滤的相似性搜索）。但是在某些情况下，用户发起的原始提问其实隐式携带了**筛选条件**，例如提问：  
请帮我整理下关于2023年全年关于AI的新闻汇总。在这段 原始提问中，如果执行相应的向量数据库相似性搜索，其实是附加了 筛选条件的，即 year=2023，但是在普通的相似性搜索中，是不会考虑 2023 年这个条件的（因为没有添加元数据过滤器，2022年和2023年数据在高维空间其实很接近），存在很大概率会将其他年份的数据也检索出来。  

**解决方案**：自查询。

![自查询](/pic/RAG优化策略/子查询.png)

```
你的任务是根据提供的信息，生成一个符合特定结构的JSON对象。该JSON对象将用于查询和过滤文档。
以下是允许使用的比较器和逻辑运算符：
<allowed_comparators>
{{ALLOWED_COMPARATORS}}
</allowed_comparators>
<allowed_operators>
{{ALLOWED_OPERATORS}}
</allowed_operators>
现在，请根据以下信息构建JSON对象：

<< Data Source >>
{{{{
    "content": "{content}",
    "attributes": {attributes}
}}}}

在构建JSON对象时，请遵循以下规则：
1. 查询字符串应仅包含预期与文档内容匹配的文本。过滤条件中的任何条件不应在查询中提及。
2. 逻辑条件语句由一个或多个比较和逻辑操作语句组成。
    - 比较语句的形式为：`comp(attr, val)`，其中`comp`为允许的比较器，`attr`为要应用比较的属性名称，`val`为比较值。
    - 逻辑操作语句的形式为：`op(statement1, statement2, ...)`，其中`op`为允许的逻辑运算符，`statement1`, `statement2`, ... 为比较语句或逻辑操作语句。
3. 仅使用上述列出的比较器和逻辑运算符，不使用其他运算符。
4. 过滤条件仅引用数据源中存在的属性。
5. 过滤条件仅使用应用了函数的属性名称及其函数名。
6. 处理日期数据类型的值时，过滤条件仅使用`YYYY - MM - DD`格式。
7. 过滤条件仅在需要时使用。如果没有要应用的过滤条件，`filter`的值应返回 "NO_FILTER"。
8. `limit`必须始终为整数类型的值。如果该参数没有意义，请留空。

请在<回答>标签内输出符合以下格式的JSON对象：
{
    "query": "文本字符串，用于与文档内容进行比较",
    "filter": "用于过滤文档的逻辑条件语句",
    "limit": 要检索的文档数量
}

<<样例>>
Data Source:
{{
    "content": "Lyrics of a song",
    "attributes": {{
        "artist": {{
            "type": "string",
            "description": "Name of the song artist"
        }},
        "length": {{
            "type": "integer",
            "description": "Length of the song in seconds"
        }},
        "genre": {{
            "type": "string",
            "description": "The song genre, one of \"pop\", \"rock\" or \"rap\""
        }}
    }}
}}

User Query:
What are songs by Taylor Swift or Katy Perry about teenage romance under 3 minutes long in the dance pop genre

Structured Request:
{{
    "query": "teenager love",
    "filter": "and(or(eq(\\"artist\\", \\"Taylor Swift\\"), eq(\\"artist\\", \\"Katy Perry\\")), lt(\\"length\\", 180), eq(\\"genre\\", \\"pop\\"))"
}}
```

## 索引

### 多表征索引

从多个维度记录该文档块的信息，增加该文档块被检索到的概率，多个维度记录信息等同于为文档块生成多个向量。  

- 把文档切割成更小的块：将一个文档块继续拆分成更小的块，通过检索小的块，定位父文档。  
- 存储摘要信息：将一个文档通过 LLM 生成摘要信息，将其和原文档一起存到向量数据库中，只返回原文档。  
- 假设性问题：使用 LLM 为每个文档块生成适合回答的假设性问题，将其和原文档一起嵌入或者代替，返回时返回原文档。  

![多表征索引](/pic/RAG优化策略/多表征索引.png)

### 分层索引

在传统的 RAG 中，我们通常依靠检索短的连续文本块来进行检索。但是，当我们处理的是长上下文时，我们就不能仅仅将文档分块嵌入到其中，或者仅仅使用上下文填充所有文档。相反，我们希望**为 LLM 的长下文找到一种好的最小化分块方法**。

![分层检索](/pic/RAG优化策略/分层检索.png)
![RAPTOR](/pic/RAG优化策略/RAPTOR.png)

检索方法：  
1. 将所有的节点都存储在一个向量数据库，折叠为一层。  
2. 从树的根节点开始，检索问题和文档的余弦相似性。  

### 切块优化

- 递归字符分割器  
- 语义文档分割器  
- 文档转换器（HTML 文档转换器、代码文档转换器、问答转换器、文档翻译器）

## 检索

### ReRank 重排序

对检索到的文档调整顺序，剔除无关/多余数据。

### 纠正性 RAG

引入了一个轻量级的检索评估器来评估检索到的文档的质量，并根据评估结果触发不同的知识检索动作，以确保生成结果的准确性。  


## 生成

### 自我反思

对原始查询、检索的内容、生成的内容进行自我反思，根据反思的结果执行不同的操作，例如：

- 直接输出答案  
- 重新检索  
- 剔除不相关的内容  
- 检测生成内容是否存在幻觉  
- 检测生成内容是否有帮助  

可以把 Self-RAG 看成是一个拥有自我反思能力的智能体，这个智能体主要用来依据相关知识库回复用户问题，自我迭代，直到输出满意的结果。

## 参考资料
https://mp.weixin.qq.com/s/NzcWykZ46oOFKRjalTuKIA